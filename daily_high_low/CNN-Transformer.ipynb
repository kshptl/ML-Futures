{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40f0aa5e-d829-409e-ac8d-8762a5212a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "17c9db98-e7a7-4869-a61b-916423d8ee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import mplfinance as mpf\n",
    "import re\n",
    "import math\n",
    "from math import floor\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import datetime as dt\n",
    "\n",
    "from dain import Adaptive_Normalizer_Layer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import MeanSquaredError\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import *#Reshape, LSTM, Dense, Bidirectional, GRU, Dropout, Input, Embedding, MultiHeadAttention, LayerNormalization, Conv1D, GlobalMaxPooling1D\n",
    "import tensorflow_probability as tfp\n",
    "from fit_one_cycle import OneCycleScheduler\n",
    "from lr_finder import LRFinder\n",
    "\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "\n",
    "df_1T = pd.read_parquet('df_CNN_LSTM_1T.parquet').reset_index().reset_index().set_index('datetime', drop=True)\n",
    "df_5T = pd.read_parquet('df_CNN_LSTM_5T.parquet')\n",
    "df_15T = pd.read_parquet('df_CNN_LSTM_15T.parquet')\n",
    "df_1H = pd.read_parquet('df_CNN_LSTM_1H.parquet')\n",
    "df_4H = pd.read_parquet('df_CNN_LSTM_4H.parquet')\n",
    "df_1B = pd.read_parquet('df_CNN_LSTM_1B.parquet').fillna(0)\n",
    "\n",
    "# df_1T = pd.read_parquet('df_CNN_LSTM_1T.parquet').reset_index().reset_index().set_index('datetime', drop=True).drop(columns=[c for c in df_1T if '_nq' in c])\n",
    "# df_5T = pd.read_parquet('df_CNN_LSTM_5T.parquet').drop(columns=[c for c in df_5T if '_nq' in c])\n",
    "# df_15T = pd.read_parquet('df_CNN_LSTM_15T.parquet').drop(columns=[c for c in df_15T if '_nq' in c])\n",
    "# df_1H = pd.read_parquet('df_CNN_LSTM_1H.parquet').drop(columns=[c for c in df_1H if '_nq' in c])\n",
    "# df_4H = pd.read_parquet('df_CNN_LSTM_4H.parquet').drop(columns=[c for c in df_4H if '_nq' in c])\n",
    "# df_1B = pd.read_parquet('df_CNN_LSTM_1B.parquet').fillna(0).drop(columns=[c for c in df_1B if '_nq' in c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7b062716-0eb2-49f8-90f3-0f4bce59bdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3627\n",
      "256 3627\n",
      "512 3627\n",
      "768 3627\n",
      "1024 3627\n",
      "1280 3627\n",
      "1536 3627\n",
      "1792 3627\n",
      "2048 3627\n",
      "2304 3627\n",
      "2560 3627\n",
      "2816 3627\n",
      "3072 3627\n",
      "3328 3627\n",
      "3584 3627\n"
     ]
    }
   ],
   "source": [
    "# Define the data generator function\n",
    "def normalize_and_yield(batch_data, batch_targets):\n",
    "    # Convert to np.array\n",
    "    batch_data = np.asarray(batch_data)\n",
    "    batch_targets = np.asarray(batch_targets)\n",
    "    \n",
    "    # Normalize\n",
    "    cols_to_standardize = ['open_es', 'high_es', 'low_es', 'close_es', 'open_nq', 'high_nq', 'low_nq', 'close_nq', 'weekly_open', 'weekly_close']\n",
    "    cols_to_standardize = [df_1B.columns.get_loc(c) for c in cols_to_standardize]\n",
    "    for i in range(batch_data.shape[1]):\n",
    "        a = batch_data[:, i, :, [0, 1, 2, 3, 7, 8, 9, 10, 24, 25]]\n",
    "        scaler = StandardScaler()\n",
    "        batch_data[:, i, :, cols_to_standardize] = scaler.fit_transform(a.reshape(-1, a.shape[-1])).reshape(a.shape[0], a.shape[1], a.shape[2])\n",
    "\n",
    "    batch_data = batch_data.astype('float32')\n",
    "    batch_data = np.split(batch_data, 6, axis=1)\n",
    "    batch_data = [element.squeeze(axis=1) for element in batch_data]\n",
    "\n",
    "    return np.asarray(batch_data), batch_targets.astype('float32')\n",
    "\n",
    "\n",
    "def data_generator(data, window_size, batch_size, indices):\n",
    "    batch_data = []\n",
    "    batch_targets = []\n",
    "    i=0\n",
    "    for index in indices:\n",
    "        dt_index = df_1T.iloc[index].name\n",
    "        input_sequences = np.array([\n",
    "            df_1T.loc[:dt_index-pd.Timedelta(minutes=1)][-window_size:].fillna(0).drop(columns='index').values.astype('float32'),\n",
    "            df_5T.loc[:dt_index-pd.Timedelta(minutes=5)][-window_size:].fillna(0).values.astype('float32'),\n",
    "            df_15T.loc[:dt_index-pd.Timedelta(minutes=15)][-window_size:].fillna(0).values.astype('float32'),\n",
    "            df_4H.loc[:dt_index-pd.Timedelta(hours=4)][-window_size:].fillna(0).values.astype('float32'),\n",
    "            df_4H.loc[:dt_index-pd.Timedelta(hours=4)][-window_size:].fillna(0).values.astype('float32'),\n",
    "            df_1B.loc[:dt_index.normalize()-pd.Timedelta(days=1)][-window_size:].fillna(0).values.astype('float32')\n",
    "        ])\n",
    "\n",
    "        # Extract the target high and low values\n",
    "        target_high = df_1T[index : index+151].high_es.max()\n",
    "        target_low = df_1T[index : index+151].low_es.min()\n",
    "\n",
    "        # Add the input sequence and targets to the batch\n",
    "        batch_data.append(input_sequences)\n",
    "        batch_targets.append([target_high, target_low])\n",
    "        print(i, len(indices)) if i % 256 == 0 else None\n",
    "        i += 1\n",
    "        \n",
    "    return normalize_and_yield(batch_data, batch_targets)\n",
    "\n",
    "\n",
    "                \n",
    "# Set the window size and batch size\n",
    "window_size = 90 # minutes in 252 days (1 year of trading days)\n",
    "batch_size = 64\n",
    "num_features = df_1T.shape[1]-1\n",
    "\n",
    "# set random seed for the shuffle function\n",
    "np.random.seed(42)\n",
    "\n",
    "# Get the indices for training, validation, and testing splits\n",
    "# Filter the indices to exclude those with insufficient historical data\n",
    "data_indices = df_1T.loc[(df_1T.index.hour == 9) & (df_1T.index.minute == 30) & (df_1T.index.dayofweek < 5) & (df_1T['index'] > df_1T[df_1B[:window_size+1].iloc[-1].name:].iloc[0]['index'].astype(int))]['index'].to_numpy()\n",
    "X, y = data_generator(df_1T, window_size, batch_size, data_indices)\n",
    "\n",
    "# Get the total number of samples and calculate the split index\n",
    "num_samples = X.shape[1]\n",
    "train_ratio = 0.9\n",
    "split_index = int(num_samples * train_ratio)\n",
    "\n",
    "# Shuffle the indices\n",
    "indices = np.arange(num_samples)#np.random.permutation(np.arange(num_samples))\n",
    "\n",
    "# Split the array based on the shuffled indices\n",
    "X_train = list(X[:, indices[:split_index], :, :])\n",
    "y_train = y[indices[:split_index]]\n",
    "X_test = list(X[:, indices[split_index:], :, :])\n",
    "y_test = y[indices[split_index:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57cac536-1541-4401-8fb9-d32ca251d3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reshape X_train to a 2D array\n",
    "# X_train = np.asarray(X_train)\n",
    "# orig_shape = X_train.shape\n",
    "\n",
    "# # Fit the scaler to the data and transform X_train\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train.reshape((-1, X_train.shape[-1])))\n",
    "\n",
    "# # Reshape X_train_scaled_2d back to the original shape\n",
    "# X_train = list(X_train.reshape(orig_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7238b97a-b5d1-4a95-9d33-7f62da532324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Transformer model\n",
    "\n",
    "# Define the input layer\n",
    "inputs_1T = Input(shape=(window_size, num_features), batch_size=batch_size)\n",
    "inputs_5T = Input(shape=(window_size, num_features), batch_size=batch_size)\n",
    "inputs_15T = Input(shape=(window_size, num_features), batch_size=batch_size)\n",
    "inputs_1H = Input(shape=(window_size, num_features), batch_size=batch_size)\n",
    "inputs_4H = Input(shape=(window_size, num_features), batch_size=batch_size)\n",
    "inputs_1B = Input(shape=(window_size, num_features), batch_size=batch_size)\n",
    "\n",
    "main_inputs = [inputs_1T, inputs_5T, inputs_15T, inputs_1H, inputs_4H, inputs_1B]\n",
    "\n",
    "# Define the Convolutional model\n",
    "timeframes = [1, 5, 15, 60, 240, 1440]  # in minutes\n",
    "conv_outputs = []\n",
    "for timeframe, inp in zip(timeframes, main_inputs):\n",
    "    x = Dense(100, activation='relu')(inp)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    x = Dense(10, activation='relu')(x)\n",
    "    x = Dense(10, activation='relu')(x)\n",
    "    conv_outputs.append(x)\n",
    "    \n",
    "# Concatenate the output\n",
    "output = Concatenate(axis=1)(conv_outputs)\n",
    "output = GlobalAveragePooling1D()(output)\n",
    "output = Dense(1)(output)\n",
    "\n",
    "# Define the model with two outputs\n",
    "model = Model(inputs=main_inputs, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mae', metrics=['mse'], run_eagerly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "62cdf476-8e13-4688-ae54-1965bf5048f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()\n",
    "#tf.keras.utils.plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "#tfp.layers.DistributionLambda(lambda t: tfp.distributions.Normal(loc=t, scale=1))(output1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8915ca-e6cb-4d76-b9d7-3cd875d63e2d",
   "metadata": {},
   "source": [
    "#### layer activations\n",
    "#### tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9a6f544f-2572-482a-95bf-5d89b049587a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kush/Documents/DS/env/lib/python3.10/site-packages/keras/src/saving/serialization_lib.py:159: UserWarning: The object being serialized includes a `lambda`. This is unsafe. In order to reload the object, you will have to pass `safe_mode=False` to the loading function. Please avoid using `lambda` in the future, and use named Python functions instead. This is the `lambda` being serialized: output = tfp.layers.DistributionLambda(lambda t: tfp.distributions.Normal(loc=t, scale=1))(output1)# Dense(1)(output1)\n",
      "\n",
      "  config_arr = [serialize_keras_object(x) for x in obj]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 8s 72ms/step - loss: 339.3975 - mse: 507621.0312 - val_loss: 66.0895 - val_mse: 5878.9541\n",
      "Epoch 2/300\n",
      " 1/91 [..............................] - ETA: 4s - loss: 27.0116 - mse: 1281.0637"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kush/Documents/DS/env/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 4s 42ms/step - loss: 26.6818 - mse: 1923.8375 - val_loss: 40.5814 - val_mse: 2537.8853\n",
      "Epoch 3/300\n",
      "91/91 [==============================] - 4s 39ms/step - loss: 32.0616 - mse: 2561.7158 - val_loss: 36.3897 - val_mse: 2137.3604\n",
      "Epoch 4/300\n",
      "91/91 [==============================] - 4s 39ms/step - loss: 29.8287 - mse: 2154.8955 - val_loss: 88.1846 - val_mse: 9404.5059\n",
      "Epoch 5/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 31.3777 - mse: 2277.0793 - val_loss: 96.8785 - val_mse: 10972.3975\n",
      "Epoch 6/300\n",
      "91/91 [==============================] - 4s 40ms/step - loss: 23.3793 - mse: 1368.8282 - val_loss: 31.1245 - val_mse: 1662.5558\n",
      "Epoch 7/300\n",
      "91/91 [==============================] - 4s 39ms/step - loss: 20.0207 - mse: 1088.3396 - val_loss: 39.1437 - val_mse: 2175.8386\n",
      "Epoch 8/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 24.4423 - mse: 1438.0593 - val_loss: 75.6079 - val_mse: 8541.3525\n",
      "Epoch 9/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 31.8177 - mse: 2069.7078 - val_loss: 67.5491 - val_mse: 5714.9790\n",
      "Epoch 10/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 19.2966 - mse: 924.8004 - val_loss: 28.4262 - val_mse: 1305.8080\n",
      "Epoch 11/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 26.1183 - mse: 1601.5579 - val_loss: 33.9666 - val_mse: 1656.9637\n",
      "Epoch 12/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 24.9371 - mse: 1505.1581 - val_loss: 129.0539 - val_mse: 21061.1895\n",
      "Epoch 13/300\n",
      "91/91 [==============================] - 4s 40ms/step - loss: 24.3991 - mse: 1445.4717 - val_loss: 26.8334 - val_mse: 1166.4066\n",
      "Epoch 14/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 37.0049 - mse: 3794.6228 - val_loss: 39.5760 - val_mse: 2213.7559\n",
      "Epoch 15/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 25.4731 - mse: 1382.6000 - val_loss: 51.0218 - val_mse: 3602.0906\n",
      "Epoch 16/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 19.8284 - mse: 922.4093 - val_loss: 26.3290 - val_mse: 1197.9417\n",
      "Epoch 17/300\n",
      "91/91 [==============================] - 4s 39ms/step - loss: 15.4503 - mse: 607.4053 - val_loss: 22.7757 - val_mse: 916.5425\n",
      "Epoch 18/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 25.9136 - mse: 1854.7955 - val_loss: 31.6837 - val_mse: 1681.7964\n",
      "Epoch 19/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 25.8216 - mse: 1641.2712 - val_loss: 200.4426 - val_mse: 46889.6602\n",
      "Epoch 20/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 23.3716 - mse: 1319.7050 - val_loss: 49.6893 - val_mse: 3710.0166\n",
      "Epoch 21/300\n",
      "91/91 [==============================] - 4s 39ms/step - loss: 16.2848 - mse: 649.8999 - val_loss: 20.4648 - val_mse: 843.4866\n",
      "Epoch 22/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 16.9135 - mse: 695.8585 - val_loss: 37.2375 - val_mse: 1743.4937\n",
      "Epoch 23/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 27.3911 - mse: 1525.5188 - val_loss: 55.1056 - val_mse: 4318.7583\n",
      "Epoch 24/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 16.9393 - mse: 647.6057 - val_loss: 19.9393 - val_mse: 767.3314\n",
      "Epoch 25/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 16.1344 - mse: 676.1780 - val_loss: 20.7916 - val_mse: 787.7452\n",
      "Epoch 26/300\n",
      "91/91 [==============================] - 4s 39ms/step - loss: 17.8553 - mse: 693.0197 - val_loss: 122.9597 - val_mse: 16859.2598\n",
      "Epoch 27/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 23.6636 - mse: 1136.2295 - val_loss: 84.1234 - val_mse: 9518.0146\n",
      "Epoch 28/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 16.3561 - mse: 580.1137 - val_loss: 20.1863 - val_mse: 734.0486\n",
      "Epoch 29/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 15.0183 - mse: 538.1779 - val_loss: 20.9149 - val_mse: 748.5949\n",
      "Epoch 30/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 17.8526 - mse: 698.8170 - val_loss: 34.3259 - val_mse: 1808.8569\n",
      "Epoch 31/300\n",
      "91/91 [==============================] - 4s 39ms/step - loss: 16.3938 - mse: 600.0962 - val_loss: 22.2940 - val_mse: 893.5159\n",
      "Epoch 32/300\n",
      "91/91 [==============================] - 4s 39ms/step - loss: 18.3623 - mse: 900.5015 - val_loss: 19.7079 - val_mse: 670.5047\n",
      "Epoch 33/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 15.3370 - mse: 498.0442 - val_loss: 41.7142 - val_mse: 2289.1599\n",
      "Epoch 34/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 20.8305 - mse: 921.6531 - val_loss: 48.9292 - val_mse: 3241.0610\n",
      "Epoch 35/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 18.7162 - mse: 806.9564 - val_loss: 25.2868 - val_mse: 1140.9380\n",
      "Epoch 36/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 11.9147 - mse: 351.3012 - val_loss: 19.2221 - val_mse: 735.5612\n",
      "Epoch 37/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 16.4684 - mse: 634.7781 - val_loss: 37.1483 - val_mse: 2137.8228\n",
      "Epoch 38/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 16.9771 - mse: 670.6893 - val_loss: 32.7522 - val_mse: 1951.3032\n",
      "Epoch 39/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 17.5085 - mse: 684.6040 - val_loss: 20.8270 - val_mse: 689.7565\n",
      "Epoch 40/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 13.2005 - mse: 398.7911 - val_loss: 27.5774 - val_mse: 1043.7163\n",
      "Epoch 41/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 18.2277 - mse: 644.0571 - val_loss: 36.3688 - val_mse: 2018.2698\n",
      "Epoch 42/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 15.3945 - mse: 523.7460 - val_loss: 29.0333 - val_mse: 1429.7063\n",
      "Epoch 43/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 15.7612 - mse: 599.8273 - val_loss: 24.1143 - val_mse: 1083.1614\n",
      "Epoch 44/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 11.8545 - mse: 351.6057 - val_loss: 44.3190 - val_mse: 2485.3140\n",
      "Epoch 45/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 15.6051 - mse: 538.6418 - val_loss: 39.4732 - val_mse: 2725.6641\n",
      "Epoch 46/300\n",
      "91/91 [==============================] - ETA: 0s - loss: 26.6349 - mse: 1623.6840\n",
      "Reducing learning rate at epoch 46 - Lowest loss: 19.2221\n",
      "Old lr_min: 0.000400, New lr_min: 0.000040\n",
      "Old final_lr: 0.0000000400, New final_lr: 0.0000000040\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 26.6349 - mse: 1623.6840 - val_loss: 23.2300 - val_mse: 851.8954\n",
      "Epoch 47/300\n",
      "91/91 [==============================] - 4s 39ms/step - loss: 8.1961 - mse: 203.1822 - val_loss: 17.8636 - val_mse: 588.7925\n",
      "Epoch 48/300\n",
      "91/91 [==============================] - 4s 39ms/step - loss: 7.7139 - mse: 191.7843 - val_loss: 17.1424 - val_mse: 601.7767\n",
      "Epoch 49/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.6941 - mse: 191.0373 - val_loss: 19.4574 - val_mse: 615.6312\n",
      "Epoch 50/300\n",
      "91/91 [==============================] - 4s 40ms/step - loss: 7.7857 - mse: 191.4075 - val_loss: 17.9417 - val_mse: 688.3906\n",
      "Epoch 51/300\n",
      "91/91 [==============================] - 4s 40ms/step - loss: 7.7604 - mse: 192.6483 - val_loss: 17.1141 - val_mse: 603.9758\n",
      "Epoch 52/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.6876 - mse: 192.8353 - val_loss: 17.1904 - val_mse: 614.7248\n",
      "Epoch 53/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.7019 - mse: 191.0389 - val_loss: 17.3165 - val_mse: 619.8130\n",
      "Epoch 54/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.6180 - mse: 188.5257 - val_loss: 17.7366 - val_mse: 578.2518\n",
      "Epoch 55/300\n",
      "91/91 [==============================] - 4s 39ms/step - loss: 8.1549 - mse: 197.6274 - val_loss: 17.7600 - val_mse: 683.1705\n",
      "Epoch 56/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.8198 - mse: 194.0220 - val_loss: 17.7227 - val_mse: 680.3355\n",
      "Epoch 57/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.6828 - mse: 188.0925 - val_loss: 17.3643 - val_mse: 611.9462\n",
      "Epoch 58/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.8313 - mse: 195.4807 - val_loss: 17.6350 - val_mse: 668.8875\n",
      "Epoch 59/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.5098 - mse: 188.1623 - val_loss: 17.0008 - val_mse: 596.4968\n",
      "Epoch 60/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.6719 - mse: 187.7906 - val_loss: 22.7477 - val_mse: 742.2288\n",
      "Epoch 61/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 8.0249 - mse: 192.9031 - val_loss: 17.0809 - val_mse: 619.2505\n",
      "Epoch 62/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 8.4282 - mse: 208.4808 - val_loss: 18.1973 - val_mse: 579.7850\n",
      "Epoch 63/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.6649 - mse: 187.0757 - val_loss: 17.4459 - val_mse: 657.8706\n",
      "Epoch 64/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.6857 - mse: 191.5497 - val_loss: 17.3373 - val_mse: 641.5849\n",
      "Epoch 65/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.8309 - mse: 191.0564 - val_loss: 17.0160 - val_mse: 594.5480\n",
      "Epoch 66/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 8.2165 - mse: 196.3296 - val_loss: 16.9898 - val_mse: 581.9652\n",
      "Epoch 67/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.6537 - mse: 187.4363 - val_loss: 17.0443 - val_mse: 579.4496\n",
      "Epoch 68/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.7802 - mse: 186.3174 - val_loss: 17.5776 - val_mse: 652.6724\n",
      "Epoch 69/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 8.0090 - mse: 191.9164 - val_loss: 17.9708 - val_mse: 574.4029\n",
      "Epoch 70/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.9499 - mse: 193.2731 - val_loss: 16.9389 - val_mse: 591.4467\n",
      "Epoch 71/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.7651 - mse: 187.6463 - val_loss: 17.1752 - val_mse: 633.1965\n",
      "Epoch 72/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 8.1063 - mse: 196.5645 - val_loss: 17.5682 - val_mse: 666.4169\n",
      "Epoch 73/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 8.4429 - mse: 198.9747 - val_loss: 17.1785 - val_mse: 568.4080\n",
      "Epoch 74/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.6817 - mse: 186.6381 - val_loss: 16.9170 - val_mse: 594.9277\n",
      "Epoch 75/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.6605 - mse: 183.0093 - val_loss: 17.4114 - val_mse: 647.5598\n",
      "Epoch 76/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 8.0633 - mse: 193.7091 - val_loss: 17.1625 - val_mse: 567.1993\n",
      "Epoch 77/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.4660 - mse: 180.2462 - val_loss: 16.9978 - val_mse: 610.7390\n",
      "Epoch 78/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.8272 - mse: 189.6064 - val_loss: 16.9349 - val_mse: 590.0338\n",
      "Epoch 79/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 8.1249 - mse: 193.6096 - val_loss: 21.2228 - val_mse: 674.0295\n",
      "Epoch 80/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.8426 - mse: 187.0092 - val_loss: 16.9752 - val_mse: 591.8095\n",
      "Epoch 81/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.6359 - mse: 182.6010 - val_loss: 16.8282 - val_mse: 581.5305\n",
      "Epoch 82/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.7521 - mse: 184.6085 - val_loss: 17.5282 - val_mse: 561.8578\n",
      "Epoch 83/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.9220 - mse: 191.1538 - val_loss: 21.0892 - val_mse: 673.7811\n",
      "Epoch 84/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 8.1215 - mse: 196.0560 - val_loss: 17.0566 - val_mse: 622.6306\n",
      "Epoch 85/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.5000 - mse: 179.0785 - val_loss: 16.7970 - val_mse: 572.9812\n",
      "Epoch 86/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.9088 - mse: 186.7742 - val_loss: 19.0185 - val_mse: 592.7936\n",
      "Epoch 87/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.8391 - mse: 185.3551 - val_loss: 17.3199 - val_mse: 581.7375\n",
      "Epoch 88/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 8.0472 - mse: 188.6443 - val_loss: 17.1636 - val_mse: 634.4650\n",
      "Epoch 89/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.9900 - mse: 188.1789 - val_loss: 18.9361 - val_mse: 589.4839\n",
      "Epoch 90/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 8.1397 - mse: 193.6983 - val_loss: 20.5641 - val_mse: 645.1576\n",
      "Epoch 91/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.9085 - mse: 184.0208 - val_loss: 17.3203 - val_mse: 555.8976\n",
      "Epoch 92/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.4557 - mse: 176.7161 - val_loss: 16.9417 - val_mse: 554.3167\n",
      "Epoch 93/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 8.1788 - mse: 193.0282 - val_loss: 17.4746 - val_mse: 556.8535\n",
      "Epoch 94/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.7657 - mse: 182.4454 - val_loss: 16.8216 - val_mse: 602.6616\n",
      "Epoch 95/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 8.3749 - mse: 194.4133 - val_loss: 16.6690 - val_mse: 573.9608\n",
      "Epoch 96/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.5155 - mse: 176.9899 - val_loss: 17.1032 - val_mse: 551.5756\n",
      "Epoch 97/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.8684 - mse: 183.6168 - val_loss: 22.9515 - val_mse: 750.6923\n",
      "Epoch 98/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 8.1695 - mse: 185.1654 - val_loss: 21.0016 - val_mse: 874.5627\n",
      "Epoch 99/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.6499 - mse: 180.1826 - val_loss: 16.7124 - val_mse: 577.8207\n",
      "Epoch 100/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.4515 - mse: 174.8666 - val_loss: 16.9500 - val_mse: 556.0898\n",
      "Epoch 101/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.4547 - mse: 178.0290 - val_loss: 19.1608 - val_mse: 608.7039\n",
      "Epoch 102/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.8528 - mse: 184.7662 - val_loss: 16.7488 - val_mse: 553.1956\n",
      "Epoch 103/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.5880 - mse: 176.5851 - val_loss: 17.0147 - val_mse: 623.4590\n",
      "Epoch 104/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.9008 - mse: 182.2361 - val_loss: 17.1098 - val_mse: 628.7422\n",
      "Epoch 105/300\n",
      "91/91 [==============================] - ETA: 0s - loss: 7.7303 - mse: 180.7113\n",
      "Reducing learning rate at epoch 105 - Lowest loss: 16.6690\n",
      "Old lr_min: 0.000040, New lr_min: 0.000004\n",
      "Old final_lr: 0.0000000040, New final_lr: 0.0000000004\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.7303 - mse: 180.7113 - val_loss: 17.6986 - val_mse: 559.8903\n",
      "Epoch 106/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.2683 - mse: 170.3466 - val_loss: 16.6771 - val_mse: 557.5421\n",
      "Epoch 107/300\n",
      "91/91 [==============================] - 4s 39ms/step - loss: 7.2629 - mse: 170.6755 - val_loss: 16.6052 - val_mse: 568.8224\n",
      "Epoch 108/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.2254 - mse: 169.9088 - val_loss: 16.6237 - val_mse: 558.1853\n",
      "Epoch 109/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.2493 - mse: 170.4062 - val_loss: 16.9887 - val_mse: 620.8511\n",
      "Epoch 110/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.2635 - mse: 172.0223 - val_loss: 16.6221 - val_mse: 568.2974\n",
      "Epoch 111/300\n",
      "91/91 [==============================] - 4s 39ms/step - loss: 7.2086 - mse: 170.2605 - val_loss: 16.6012 - val_mse: 567.6052\n",
      "Epoch 112/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.2112 - mse: 170.6643 - val_loss: 16.6524 - val_mse: 572.8222\n",
      "Epoch 113/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.2465 - mse: 171.0745 - val_loss: 16.7023 - val_mse: 551.9382\n",
      "Epoch 114/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.2274 - mse: 171.0447 - val_loss: 16.6290 - val_mse: 577.5193\n",
      "Epoch 115/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.2442 - mse: 170.2420 - val_loss: 16.6384 - val_mse: 562.6285\n",
      "Epoch 116/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.1980 - mse: 169.5203 - val_loss: 16.6286 - val_mse: 577.3397\n",
      "Epoch 117/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.2336 - mse: 171.0545 - val_loss: 16.6127 - val_mse: 559.9300\n",
      "Epoch 118/300\n",
      "91/91 [==============================] - 4s 39ms/step - loss: 7.2387 - mse: 169.9871 - val_loss: 16.5894 - val_mse: 567.0274\n",
      "Epoch 119/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.2288 - mse: 170.6284 - val_loss: 16.5898 - val_mse: 568.8426\n",
      "Epoch 120/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.2304 - mse: 170.1568 - val_loss: 16.6840 - val_mse: 584.6693\n",
      "Epoch 121/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.2685 - mse: 171.2059 - val_loss: 16.5883 - val_mse: 568.5177\n",
      "Epoch 122/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.2075 - mse: 169.2721 - val_loss: 16.5925 - val_mse: 570.7465\n",
      "Epoch 123/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.2384 - mse: 170.8823 - val_loss: 16.7736 - val_mse: 601.6686\n",
      "Epoch 124/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.2531 - mse: 171.2321 - val_loss: 16.5973 - val_mse: 569.7571\n",
      "Epoch 125/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.2139 - mse: 169.9465 - val_loss: 16.5909 - val_mse: 568.7373\n",
      "Epoch 126/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.2199 - mse: 170.2832 - val_loss: 16.6285 - val_mse: 578.6813\n",
      "Epoch 127/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.2079 - mse: 169.2348 - val_loss: 17.0391 - val_mse: 627.6155\n",
      "Epoch 128/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.2507 - mse: 171.1505 - val_loss: 16.6301 - val_mse: 578.5944\n",
      "Epoch 129/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.2039 - mse: 169.0744 - val_loss: 16.5841 - val_mse: 567.0056\n",
      "Epoch 130/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.2350 - mse: 170.2787 - val_loss: 16.6480 - val_mse: 584.1022\n",
      "Epoch 131/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.2941 - mse: 170.6725 - val_loss: 16.8947 - val_mse: 614.6388\n",
      "Epoch 132/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.2131 - mse: 169.9251 - val_loss: 16.5873 - val_mse: 572.1138\n",
      "Epoch 133/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.2517 - mse: 170.5033 - val_loss: 16.6156 - val_mse: 556.7328\n",
      "Epoch 134/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.1994 - mse: 168.8613 - val_loss: 16.6723 - val_mse: 551.0088\n",
      "Epoch 135/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.2444 - mse: 170.1086 - val_loss: 16.6520 - val_mse: 581.9216\n",
      "Epoch 136/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.2210 - mse: 169.4952 - val_loss: 16.5903 - val_mse: 561.2360\n",
      "Epoch 137/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.2120 - mse: 168.7863 - val_loss: 16.6400 - val_mse: 582.0908\n",
      "Epoch 138/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.2071 - mse: 169.4344 - val_loss: 16.6713 - val_mse: 556.0517\n",
      "Epoch 139/300\n",
      "91/91 [==============================] - ETA: 0s - loss: 7.2522 - mse: 170.0380\n",
      "Reducing learning rate at epoch 139 - Lowest loss: 16.5841\n",
      "Old lr_min: 0.000004, New lr_min: 0.000000\n",
      "Old final_lr: 0.0000000004, New final_lr: 0.0000000000\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.2522 - mse: 170.0380 - val_loss: 17.1278 - val_mse: 635.1474\n",
      "Epoch 140/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.2025 - mse: 169.7477 - val_loss: 16.5902 - val_mse: 570.8187\n",
      "Epoch 141/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.1832 - mse: 167.8913 - val_loss: 16.5802 - val_mse: 559.8260\n",
      "Epoch 142/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.1828 - mse: 168.4518 - val_loss: 16.5696 - val_mse: 565.2469\n",
      "Epoch 143/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.1819 - mse: 168.3654 - val_loss: 16.6038 - val_mse: 577.2891\n",
      "Epoch 144/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.1858 - mse: 170.2818 - val_loss: 16.5883 - val_mse: 573.7475\n",
      "Epoch 145/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.1812 - mse: 168.9263 - val_loss: 16.5687 - val_mse: 566.7701\n",
      "Epoch 146/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.1922 - mse: 167.4390 - val_loss: 16.6444 - val_mse: 585.3531\n",
      "Epoch 147/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.1771 - mse: 169.1989 - val_loss: 16.7188 - val_mse: 594.6765\n",
      "Epoch 148/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.1873 - mse: 170.0344 - val_loss: 16.5821 - val_mse: 572.9451\n",
      "Epoch 149/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.1744 - mse: 168.5517 - val_loss: 16.5762 - val_mse: 569.2394\n",
      "Epoch 150/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.1730 - mse: 168.5515 - val_loss: 16.6016 - val_mse: 576.8679\n",
      "Epoch 151/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.1684 - mse: 168.4152 - val_loss: 16.5737 - val_mse: 565.8081\n",
      "Epoch 152/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.1680 - mse: 168.6503 - val_loss: 16.5876 - val_mse: 573.6258\n",
      "Epoch 153/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.1790 - mse: 168.8787 - val_loss: 16.5780 - val_mse: 565.3300\n",
      "Epoch 154/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.1739 - mse: 168.0633 - val_loss: 16.6509 - val_mse: 586.3570\n",
      "Epoch 155/300\n",
      "91/91 [==============================] - ETA: 0s - loss: 7.1761 - mse: 168.9634\n",
      "Reducing learning rate at epoch 155 - Lowest loss: 16.5687\n",
      "Old lr_min: 0.000000, New lr_min: 0.000000\n",
      "Old final_lr: 0.0000000000, New final_lr: 0.0000000000\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.1761 - mse: 168.9634 - val_loss: 16.5757 - val_mse: 563.0095\n",
      "Epoch 156/300\n",
      "91/91 [==============================] - 4s 39ms/step - loss: 7.1726 - mse: 167.9442 - val_loss: 16.5722 - val_mse: 567.2125\n",
      "Epoch 157/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.1694 - mse: 168.0305 - val_loss: 16.5703 - val_mse: 565.5829\n",
      "Epoch 158/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.1688 - mse: 168.6721 - val_loss: 16.5743 - val_mse: 569.2091\n",
      "Epoch 159/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.1706 - mse: 168.3749 - val_loss: 16.5776 - val_mse: 570.5682\n",
      "Epoch 160/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.1648 - mse: 168.7874 - val_loss: 16.5745 - val_mse: 569.4138\n",
      "Epoch 161/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.1767 - mse: 168.5451 - val_loss: 16.5712 - val_mse: 567.9626\n",
      "Epoch 162/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.1690 - mse: 168.5824 - val_loss: 16.5726 - val_mse: 568.8347\n",
      "Epoch 163/300\n",
      "91/91 [==============================] - 3s 38ms/step - loss: 7.1777 - mse: 168.7760 - val_loss: 16.5724 - val_mse: 568.8472\n",
      "Epoch 164/300\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.1718 - mse: 168.5345 - val_loss: 16.5698 - val_mse: 567.2573\n",
      "Epoch 165/300\n",
      "91/91 [==============================] - ETA: 0s - loss: 7.1774 - mse: 169.1205\n",
      "Reducing learning rate at epoch 165 - Lowest loss: 16.5687\n",
      "Old lr_min: 0.000000, New lr_min: 0.000000\n",
      "Old final_lr: 0.0000000000, New final_lr: 0.0000000000\n",
      "91/91 [==============================] - 3s 37ms/step - loss: 7.1774 - mse: 169.1205 - val_loss: 16.5810 - val_mse: 571.6720\n",
      "Lowest loss achieved: 16.5687\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 300\n",
    "lr = 1e-2\n",
    "\n",
    "train_steps_per_epoch = len(X_train[0]) // batch_size\n",
    "\n",
    "#lr_schedule = OneCycleScheduler(lr, train_steps_per_epoch)\n",
    "lr_schedule = OneCycleScheduler(lr_max=lr, steps=train_steps_per_epoch, reduce_lr_patience=10, reduce_lr_factor=0.1)\n",
    "lr_finder = LRFinder()\n",
    "\n",
    "# Define the ReduceLROnPlateau callback\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=10)\n",
    "\n",
    "\n",
    "log_dir = \"logs/fit/\" + dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# Define the Early Stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor for early stopping\n",
    "    patience=20,  # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore the best model weights based on the monitored metric\n",
    ")\n",
    "\n",
    "# Define the ModelCheckpoint callback to save the best model during training\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model_test.h5',  # Filepath to save the best model\n",
    "    monitor='val_loss',  # Metric to monitor for saving the best model\n",
    "    save_best_only=True  # Save only the best model based on the monitored metric\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, y_train[:,1], epochs=epochs, validation_split=0.11111,\n",
    "                    callbacks=[lr_schedule, early_stopping, tensorboard_callback, checkpoint])\n",
    "\n",
    "# Plot the training and validation loss and MAE\n",
    "plt.semilogy(history.history['loss'], label='mae')\n",
    "plt.semilogy(history.history['val_loss'], label='val_mae')\n",
    "plt.ylim(ymin=1)  # Set the y-axis minimum value to 0\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ae9a97f2-4ec5-4365-ba03-dccb6585f56d",
   "metadata": {},
   "source": [
    "Epoch 29/30\n",
    "78/78 [==============================] - 83s 1s/step - loss: 4494.5864 - mae: 47.1393 - val_loss: 5005.4351 - val_mae: 52.9623\n",
    "- Conv1D(filters=128, kernel_size=5, strides=1, activation='sigmoid', kernel_initializer='glorot_uniform')(inputs)\n",
    "- tf.keras.layers.MultiHeadAttention(num_heads=2, key_dim=4, kernel_initializer='glorot_uniform')(conv_layer, conv_layer, conv_layer)\n",
    "\n",
    "Epoch 25/30\n",
    "78/78 [==============================] - 94s 1s/step - loss: 4547.9351 - mae: 45.7742 - val_loss: 7434.1909 - val_mae: 59.7734\n",
    "- Conv1D(filters=128, kernel_size=5, strides=1, activation='sigmoid', kernel_initializer='glorot_uniform')(inputs)\n",
    "- tf.keras.layers.MultiHeadAttention(num_heads=4, key_dim=8, kernel_initializer='glorot_uniform')(conv_layer, conv_layer, conv_layer)\n",
    "\n",
    "Epoch 18/30 - TRAINING GOT STUCK\n",
    "78/78 [==============================] - 86s 1s/step - loss: 6820.2021 - mae: 59.7457 - val_loss: 10356.0488 - val_mae: 74.6960\n",
    "- Conv1D(filters=256, kernel_size=5, strides=1, activation='sigmoid', kernel_initializer='glorot_uniform')(inputs)\n",
    "- tf.keras.layers.MultiHeadAttention(num_heads=4, key_dim=8, kernel_initializer='glorot_uniform')(conv_layer, conv_layer, conv_layer)\n",
    "\n",
    "Epoch 28/30\n",
    "78/78 [==============================] - 87s 1s/step - loss: 6216.4541 - mae: 55.8392 - val_loss: 5582.3062 - val_mae: 55.9733\n",
    "- Conv1D(filters=128, kernel_size=5, strides=1, activation='tanh', kernel_initializer='glorot_uniform')(inputs)\n",
    "- tf.keras.layers.MultiHeadAttention(num_heads=2, key_dim=4, kernel_initializer='glorot_uniform')(conv_layer, conv_layer, conv_layer)\n",
    "\n",
    "One Hot encoding FVG columns\n",
    "Epoch 17/30\n",
    "71/71 [==============================] - 48s 673ms/step - loss: 38636.7422 - mae: 141.6401 - val_loss: 13221.0039 - val_mae: 79.1011\n",
    "- Conv1D(filters=128, kernel_size=5, strides=1, activation='tanh', kernel_initializer='glorot_uniform')(inputs)\n",
    "- tf.keras.layers.MultiHeadAttention(num_heads=2, key_dim=4, kernel_initializer='glorot_uniform')(conv_layer, conv_layer, conv_layer)\n",
    "\n",
    "1T-5T FVG included\n",
    "Epoch 23/30\n",
    "71/71 [==============================] - 43s 600ms/step - loss: 41062.0117 - mae: 143.3411 - val_loss: 15992.5898 - val_mae: 80.2741\n",
    "- Conv1D(filters=128, kernel_size=5, strides=1, activation='tanh', kernel_initializer='glorot_uniform')(inputs)\n",
    "- tf.keras.layers.MultiHeadAttention(num_heads=2, key_dim=4, kernel_initializer='glorot_uniform')(conv_layer, conv_layer, conv_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c1fcc7c7-023d-4926-99f6-5f1487f34394",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 70ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4a8e5141-593d-4b72-bd62-99b162eb16f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-29.21875  , -19.44043  , -14.211914 , -20.171875 , -18.105469 ,\n",
       "       -10.8359375, -11.013184 , -28.493652 , -44.34912  , -22.253906 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[4] - y_test[4][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e753bca2-cab3-4d2e-bf9b-d443008fcbc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4643.941 , 4605.2266], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1d9ead58-3e78-4192-abc4-5f6bc2b08ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 49ms/step\n",
      "12/12 [==============================] - 1s 59ms/step\n"
     ]
    }
   ],
   "source": [
    "#test_steps = len(test_indices) // batch_size\n",
    "# Generate predictions for the test set\n",
    "high_model = tf.keras.saving.load_model('best_model_high.h5')\n",
    "low_model = tf.keras.saving.load_model('best_model_low.h5')\n",
    "\n",
    "high_predictions = high_model.predict(X_test)\n",
    "low_predictions = low_model.predict(X_test)\n",
    "\n",
    "# Create a dictionary with the arrays\n",
    "data = {\n",
    "    'date': df_1T.iloc[data_indices[split_index:]].index.date,\n",
    "    'ph': high_predictions.reshape(len(high_predictions)),\n",
    "    'h': y_test[:,0].reshape(len(y_test[:,0])),\n",
    "    'pl': low_predictions.reshape(len(low_predictions)),\n",
    "    'l': y_test[:,1].reshape(len(y_test[:,1]))\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "res = pd.DataFrame(data)\n",
    "\n",
    "# Print the individual predictions with actual values\n",
    "# for i in range(len(predicted_high)):\n",
    "#     print(f\"Sample {i+1} - {dates[i]} - Predicted/Actual High: {predicted_high[i]:.2f}, {actual_high[i]:.2f} Predicted/Actual Low: {predicted_low[i]:.2f}, {actual_low[i]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5f6d7d4a-fcaf-4c44-b2e2-12f5ba8e5877",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ph</th>\n",
       "      <th>h</th>\n",
       "      <th>pl</th>\n",
       "      <th>l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>4883.118652</td>\n",
       "      <td>4881.830566</td>\n",
       "      <td>4857.714355</td>\n",
       "      <td>4859.671387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>4870.245605</td>\n",
       "      <td>4868.331543</td>\n",
       "      <td>4842.684082</td>\n",
       "      <td>4847.445801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>4880.989746</td>\n",
       "      <td>4878.264648</td>\n",
       "      <td>4853.069336</td>\n",
       "      <td>4859.671387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2022-01-17</td>\n",
       "      <td>4757.654785</td>\n",
       "      <td>4748.113281</td>\n",
       "      <td>4731.143555</td>\n",
       "      <td>4737.925293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2022-06-15</td>\n",
       "      <td>3878.179932</td>\n",
       "      <td>3877.089844</td>\n",
       "      <td>3842.307861</td>\n",
       "      <td>3842.124512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2022-06-20</td>\n",
       "      <td>3805.701660</td>\n",
       "      <td>3802.820068</td>\n",
       "      <td>3770.771240</td>\n",
       "      <td>3774.490479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2022-07-04</td>\n",
       "      <td>3904.745605</td>\n",
       "      <td>3899.294434</td>\n",
       "      <td>3874.506104</td>\n",
       "      <td>3885.257080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2022-07-25</td>\n",
       "      <td>4060.179199</td>\n",
       "      <td>4060.084717</td>\n",
       "      <td>4031.147461</td>\n",
       "      <td>4033.541504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2022-09-21</td>\n",
       "      <td>3974.844238</td>\n",
       "      <td>3969.251709</td>\n",
       "      <td>3945.655029</td>\n",
       "      <td>3949.939209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>2022-11-24</td>\n",
       "      <td>4112.502930</td>\n",
       "      <td>4114.096680</td>\n",
       "      <td>4098.526855</td>\n",
       "      <td>4108.505859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>2022-11-25</td>\n",
       "      <td>4110.441406</td>\n",
       "      <td>4105.710938</td>\n",
       "      <td>4091.077637</td>\n",
       "      <td>4091.480469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>2023-01-16</td>\n",
       "      <td>4062.007568</td>\n",
       "      <td>4053.431641</td>\n",
       "      <td>4043.984131</td>\n",
       "      <td>4043.349609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>4153.801758</td>\n",
       "      <td>4142.750000</td>\n",
       "      <td>4129.761230</td>\n",
       "      <td>4128.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>2023-04-19</td>\n",
       "      <td>4179.041992</td>\n",
       "      <td>4175.250000</td>\n",
       "      <td>4156.448242</td>\n",
       "      <td>4157.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>2023-05-08</td>\n",
       "      <td>4160.809082</td>\n",
       "      <td>4156.250000</td>\n",
       "      <td>4139.449219</td>\n",
       "      <td>4141.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date           ph            h           pl            l\n",
       "7    2021-12-29  4883.118652  4881.830566  4857.714355  4859.671387\n",
       "9    2021-12-31  4870.245605  4868.331543  4842.684082  4847.445801\n",
       "12   2022-01-05  4880.989746  4878.264648  4853.069336  4859.671387\n",
       "20   2022-01-17  4757.654785  4748.113281  4731.143555  4737.925293\n",
       "126  2022-06-15  3878.179932  3877.089844  3842.307861  3842.124512\n",
       "129  2022-06-20  3805.701660  3802.820068  3770.771240  3774.490479\n",
       "139  2022-07-04  3904.745605  3899.294434  3874.506104  3885.257080\n",
       "154  2022-07-25  4060.179199  4060.084717  4031.147461  4033.541504\n",
       "196  2022-09-21  3974.844238  3969.251709  3945.655029  3949.939209\n",
       "242  2022-11-24  4112.502930  4114.096680  4098.526855  4108.505859\n",
       "243  2022-11-25  4110.441406  4105.710938  4091.077637  4091.480469\n",
       "277  2023-01-16  4062.007568  4053.431641  4043.984131  4043.349609\n",
       "337  2023-04-11  4153.801758  4142.750000  4129.761230  4128.750000\n",
       "343  2023-04-19  4179.041992  4175.250000  4156.448242  4157.750000\n",
       "356  2023-05-08  4160.809082  4156.250000  4139.449219  4141.500000"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.query('(h < ph + 2) and (l > pl - 2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1028ffbd-ad4c-4325-99f2-d0d8b40a5c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b7fb56c2-0a0b-4b1a-8395-35541b0f1ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 2s 20ms/step\n",
      "102/102 [==============================] - 2s 20ms/step\n",
      "102/102 [==============================] - 2s 19ms/step\n",
      "102/102 [==============================] - 2s 19ms/step\n",
      "102/102 [==============================] - 2s 21ms/step\n",
      "102/102 [==============================] - 2s 21ms/step\n",
      "102/102 [==============================] - 2s 18ms/step\n",
      "102/102 [==============================] - 2s 20ms/step\n",
      "102/102 [==============================] - 2s 21ms/step\n",
      "102/102 [==============================] - 2s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "# Bootstrap sampling and predictions\n",
    "num_bootstrap_samples = 10  # Number of bootstrap samples\n",
    "predictions = []\n",
    "\n",
    "for _ in range(num_bootstrap_samples):\n",
    "    # Create a bootstrap sample by randomly selecting inputs with replacement\n",
    "    input_indices = np.random.choice(X_train[0].shape[0], size=X_train[0].shape[0], replace=True)\n",
    "    X_bootstrap = list(np.array(X_train)[:, input_indices, :, :])\n",
    "    y_bootstrap = list(np.array(y_train)[input_indices])\n",
    "    \n",
    "    # Make predictions on the bootstrap sample\n",
    "    y_pred = model.predict(X_bootstrap)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "# Compute uncertainty or confidence intervals\n",
    "predictions = np.array(predictions)\n",
    "prediction_mean = np.mean(predictions, axis=0)\n",
    "prediction_std = np.std(predictions, axis=0)\n",
    "lower_bound = np.percentile(predictions, 5, axis=0)\n",
    "upper_bound = np.percentile(predictions, 95, axis=0)\n",
    "\n",
    "# Use the computed uncertainty estimates as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "86634562-fbd9-43c5-9910-febbfdd9eac3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ph</th>\n",
       "      <th>h</th>\n",
       "      <th>lb</th>\n",
       "      <th>ub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-04-20</td>\n",
       "      <td>1867.890259</td>\n",
       "      <td>761.405457</td>\n",
       "      <td>909.965509</td>\n",
       "      <td>3364.113098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-04-21</td>\n",
       "      <td>2109.597656</td>\n",
       "      <td>750.011169</td>\n",
       "      <td>1190.764783</td>\n",
       "      <td>3737.402173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-04-22</td>\n",
       "      <td>1962.464844</td>\n",
       "      <td>765.650391</td>\n",
       "      <td>1092.418225</td>\n",
       "      <td>3023.298401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-04-23</td>\n",
       "      <td>2015.708618</td>\n",
       "      <td>755.149780</td>\n",
       "      <td>958.864169</td>\n",
       "      <td>3766.523926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-04-24</td>\n",
       "      <td>2074.220215</td>\n",
       "      <td>771.906067</td>\n",
       "      <td>861.244061</td>\n",
       "      <td>3220.950500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>2021-12-10</td>\n",
       "      <td>2209.707275</td>\n",
       "      <td>4786.063477</td>\n",
       "      <td>996.143845</td>\n",
       "      <td>3313.968958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>2021-12-13</td>\n",
       "      <td>1930.743164</td>\n",
       "      <td>4789.883789</td>\n",
       "      <td>893.195697</td>\n",
       "      <td>3849.656775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>2012.803467</td>\n",
       "      <td>4739.453125</td>\n",
       "      <td>1107.047205</td>\n",
       "      <td>3151.410950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>2021-12-15</td>\n",
       "      <td>2402.161133</td>\n",
       "      <td>4719.077148</td>\n",
       "      <td>1007.157309</td>\n",
       "      <td>4617.963354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263</th>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2020.747803</td>\n",
       "      <td>4812.042480</td>\n",
       "      <td>857.666760</td>\n",
       "      <td>3330.711084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3264 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date           ph            h           lb           ub\n",
       "0     2009-04-20  1867.890259   761.405457   909.965509  3364.113098\n",
       "1     2009-04-21  2109.597656   750.011169  1190.764783  3737.402173\n",
       "2     2009-04-22  1962.464844   765.650391  1092.418225  3023.298401\n",
       "3     2009-04-23  2015.708618   755.149780   958.864169  3766.523926\n",
       "4     2009-04-24  2074.220215   771.906067   861.244061  3220.950500\n",
       "...          ...          ...          ...          ...          ...\n",
       "3259  2021-12-10  2209.707275  4786.063477   996.143845  3313.968958\n",
       "3260  2021-12-13  1930.743164  4789.883789   893.195697  3849.656775\n",
       "3261  2021-12-14  2012.803467  4739.453125  1107.047205  3151.410950\n",
       "3262  2021-12-15  2402.161133  4719.077148  1007.157309  4617.963354\n",
       "3263  2021-12-16  2020.747803  4812.042480   857.666760  3330.711084\n",
       "\n",
       "[3264 rows x 5 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = {\n",
    "    'date': df_1T.iloc[data_indices[:split_index]].index.date,\n",
    "    'ph': predictions.mean(axis=0).reshape(predictions.shape[1]),\n",
    "    'h': y_train.reshape(len(y_train))\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "train_res = pd.DataFrame(train_data)\n",
    "\n",
    "train_res['lb'] = lower_bound\n",
    "train_res['ub'] = upper_bound\n",
    "train_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bb9742d7-3b24-45ab-b9d1-72f709818469",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1021.78235],\n",
       "       [ 818.479  ],\n",
       "       [2167.984  ],\n",
       "       [1219.759  ],\n",
       "       [2181.5437 ],\n",
       "       [1039.2534 ],\n",
       "       [3335.5208 ],\n",
       "       [1516.9125 ],\n",
       "       [3387.5068 ],\n",
       "       [1990.1626 ]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206d31ce-9010-408e-8b60-c36a6fca8636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
